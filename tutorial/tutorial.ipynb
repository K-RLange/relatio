{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10bb6bdd",
   "metadata": {},
   "source": [
    "# An introduction to `relatio` \n",
    "**Runtime $\\sim$ 1h**\n",
    "\n",
    "Original paper: [\"Text Semantics Capture Political and Economic Narratives\"](https://arxiv.org/abs/2108.01720)\n",
    "\n",
    "----------------------------\n",
    "\n",
    "This is a short demo of the package `relatio`.  It takes as input a text corpus and outputs a list of narrative statements. The pipeline is unsupervised: the user does not need to specify narratives beforehand. Narrative statements are defined as tuples of semantic roles with a (agent, verb, patient, attribute) structure. \n",
    "\n",
    "Here, we present the main wrapper functions to quickly obtain narrative statements from a corpus.\n",
    "\n",
    "----------------------------\n",
    "\n",
    "We provide datasets that have already been split into sentences and annotated by our team.\n",
    "\n",
    "The datasets are provided in three different formats:\n",
    " 1. `raw` (unprocessed)\n",
    " 2. `split_sentences` (as a list of sentences)\n",
    " 3. `srl` (as a list of annotated sentences by the semantic role labeler)\n",
    "\n",
    "In this tutorial, we work with the Trump Tweet Archive corpus.\n",
    "\n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7121f11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17886d5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-07 14:03:28.094156: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-07 14:03:28.094175: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# Catch warnings for an easy ride\n",
    "from relatio import FileLogger\n",
    "logger = FileLogger(level = 'WARNING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1fe7218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    List of available datasets:\n",
      "\n",
      "    Trump Tweet Archive\n",
      "    - function call: load_trump_data()\n",
      "    - format: 'raw', 'split_sentences', 'srl_res'\n",
      "    - allennlp version: 0.9\n",
      "    - srl model: srl-model-2018.05.25.tar.gz\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Browse list of available datasets\n",
    "from relatio.datasets import list_datasets\n",
    "print(list_datasets())\n",
    "\n",
    "# Load an available dataset\n",
    "from relatio.datasets import load_trump_data\n",
    "df = load_trump_data(\"raw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e04ad8d",
   "metadata": {},
   "source": [
    "## Step 1: Split into sentences\n",
    "\n",
    "----------------------------\n",
    "\n",
    "For any new corpus, the first thing you will want to do is to split the corpus into sentences.\n",
    "\n",
    "We do this on the first 100 tweets. \n",
    "\n",
    "The output is two lists: one with an index for the document and one with the resulting split sentences.\n",
    "\n",
    "----------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d00439a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting into sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 342.05it/s]\n"
     ]
    }
   ],
   "source": [
    "from relatio.preprocessing import *\n",
    "\n",
    "p = Preprocessor(\n",
    "    spacy_model = \"en_core_web_md\",\n",
    "    remove_punctuation = True,\n",
    "    remove_digits = True,\n",
    "    lowercase = True,\n",
    "    lemmatize = True,\n",
    "    remove_chars = None,\n",
    "    stop_words = [],\n",
    "    n_process = -1,\n",
    "    batch_size = 100\n",
    ")\n",
    "\n",
    "split_sentences = p.split_into_sentences(\n",
    "    df.iloc[0:100], output_path='sentences.json', progress_bar=True\n",
    ")\n",
    "\n",
    "from relatio.utils import load_sentences\n",
    "doc_index, sentences = load_sentences('sentences.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcd1100",
   "metadata": {},
   "source": [
    "## Step 2: Annotate semantic roles\n",
    "\n",
    "----------------------------\n",
    "\n",
    "Once the corpus is split into sentences. You can feed it to the semantic role labeler.\n",
    "\n",
    "The output is a list of json objects which contain the semantic role annotations for each sentence in the corpus.\n",
    "\n",
    "----------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cacb0860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running SRL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:05<00:00,  3.89it/s]\n"
     ]
    }
   ],
   "source": [
    "from relatio.semantic_role_labeling import SRL\n",
    "\n",
    "SRL = SRL(\n",
    "    path = \"https://storage.googleapis.com/allennlp-public-models/openie-model.2020.03.26.tar.gz\",\n",
    "    batch_size = 10,\n",
    "    cuda_device = -1\n",
    ")\n",
    "\n",
    "srl_res = SRL(split_sentences[1], progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc80c071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbs': [{'verb': 'have',\n",
       "   'description': 'Republicans and Democrats [V: have] both created our economic problems .',\n",
       "   'tags': ['O', 'O', 'O', 'B-V', 'O', 'O', 'O', 'O', 'O', 'O']},\n",
       "  {'verb': 'created',\n",
       "   'description': '[ARG0: Republicans and Democrats] have both [V: created] [ARG1: our economic problems] .',\n",
       "   'tags': ['B-ARG0',\n",
       "    'I-ARG0',\n",
       "    'I-ARG0',\n",
       "    'O',\n",
       "    'O',\n",
       "    'B-V',\n",
       "    'B-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'O']}],\n",
       " 'words': ['Republicans',\n",
       "  'and',\n",
       "  'Democrats',\n",
       "  'have',\n",
       "  'both',\n",
       "  'created',\n",
       "  'our',\n",
       "  'economic',\n",
       "  'problems',\n",
       "  '.']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srl_res[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e112b6",
   "metadata": {},
   "source": [
    "NB: This step is faster with a GPU. The argument cuda_device allows users to use their GPUs:\n",
    "\n",
    "```\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())\n",
    "\n",
    "SRL = SRL(\n",
    "    path = \"https://storage.googleapis.com/allennlp-public-models/openie-model.2020.03.26.tar.gz\",\n",
    "    batch_size = 10,\n",
    "    cuda_device = 0\n",
    ")\n",
    "\n",
    "srl_res = SRL(split_sentences[1], progress_bar=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e546d4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save us some time, we download the results from the datasets module.\n",
    "# split_sentences = load_trump_data(\"split_sentences\")\n",
    "# srl_res = load_trump_data(\"srl_res\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28629041",
   "metadata": {},
   "source": [
    "## Step 3: Pre-process semantic roles\n",
    "\n",
    "----------------------------\n",
    "\n",
    "\n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cb56070",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting semantic roles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 205/205 [00:00<00:00, 21833.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-V': 'have'}\n",
      "{'ARG0': 'Republicans and Democrats', 'ARG1': 'our economic problems', 'B-V': 'created'}\n",
      "{'ARG1': 'I', 'ARG2': 'thrilled to be back in the Great city of Charlotte , North Carolina with thousands of hardworking American Patriots who love our Country , cherish our values , respect our laws , and always put AMERICA FIRST', 'B-V': 'was'}\n",
      "{'ARG1': 'I', 'ARG2': 'back in the Great city of Charlotte , North Carolina with , respect our laws , and always put AMERICA FIRST', 'B-V': 'be'}\n",
      "{'ARG0': 'thousands of hardworking American Patriots who', 'ARG1': 'our Country', 'B-V': 'love'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from relatio.semantic_role_labeling import extract_roles\n",
    "\n",
    "roles, sentence_index = extract_roles(\n",
    "    srl_res, \n",
    "    used_roles = [\"ARG0\",\"B-V\",\"B-ARGM-NEG\",\"B-ARGM-MOD\",\"ARG1\",\"ARG2\"],\n",
    "    progress_bar = True\n",
    ")\n",
    "\n",
    "for d in roles[0:5]: print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "478392f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning phrases for role ARG0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 136/136 [00:00<00:00, 495.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning phrases for role B-V...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 377/377 [00:00<00:00, 956.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning phrases for role B-ARGM-MOD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 30/30 [00:00<00:00, 109.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning phrases for role ARG1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 258/258 [00:00<00:00, 672.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning phrases for role ARG2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 71/71 [00:00<00:00, 258.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-V': 'have'}\n",
      "{'ARG0': 'republicans democrats', 'B-V': 'create', 'ARG1': 'problem'}\n",
      "{'ARG2': 'cit charlotte north carolina thousand patriots countr value law america'}\n",
      "{'ARG2': 'cit charlotte north carolina law america'}\n",
      "{'ARG0': 'thousand patriots', 'ARG1': 'countr'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "postproc_roles = p.process_roles(roles, \n",
    "                                 dict_of_pos_tags_to_keep = {\n",
    "                                     \"ARG0\": ['NOUN', 'PROPN'],\n",
    "                                     \"B-V\": ['VERB'],\n",
    "                                     \"ARG1\": ['NOUN', 'PROPN'],\n",
    "                                     \"ARG2\": ['NOUN', 'PROPN']\n",
    "                                 }, \n",
    "                                 progress_bar = True,\n",
    "                                 output_path = 'postproc_roles.json')\n",
    "\n",
    "from relatio.utils import load_roles\n",
    "postproc_roles = load_roles('postproc_roles.json')\n",
    "\n",
    "for d in postproc_roles[0:5]: print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e627dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_entities = p.mine_entities(\n",
    "    split_sentences[1], \n",
    "    clean_entities = True, \n",
    "    progress_bar = True,\n",
    "    output_path = 'entities.pkl'\n",
    ")\n",
    "\n",
    "from relatio.utils import load_entities\n",
    "known_entities = load_entities('entities.pkl')\n",
    "\n",
    "for n in known_entities.most_common(10): print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad2f93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_known_entities = [e[0] for e in list(known_entities.most_common(100)) if e[0] != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fc61ab",
   "metadata": {},
   "source": [
    "## Step 4: Build a narrative model\n",
    "\n",
    "----------------------------\n",
    "\n",
    "We are now ready to build a narrative model.\n",
    "\n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2f75d13d",
   "metadata": {},
   "source": [
    "postproc_roles = [{'B-V': 'have'},\n",
    " {'ARG0': 'republicans democrats', 'B-V': 'create', 'ARG1': 'problem'},\n",
    " {'ARG2': 'city charlotte north carolina thousand patriots country value law america'},\n",
    " {'ARG2': 'city charlotte north carolina law america'},\n",
    " {'ARG0': 'thousand patriots', 'ARG1': 'country'},\n",
    " {'ARG0': 'thousand patriots', 'B-V': 'cherish', 'ARG1': 'value'},\n",
    " {'ARG1': 'law'},\n",
    " {'B-V': 'put', 'ARG1': 'america first'},\n",
    " {'B-V': 'thank', 'ARG2': 'evening'},\n",
    " {'ARG1': 'unsolicited mail ballot scam', 'ARG2': 'threat democracy amp'}]\n",
    "\n",
    "top_known_entities = ['republicans', 'democrats', 'mail allot scam', 'america', 'thousand patriots']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee9d9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from relatio.narrative_models import NarrativeModel\n",
    "from relatio.utils import prettify\n",
    "from collections import Counter\n",
    "\n",
    "m = NarrativeModel(model_type = 'deterministic',\n",
    "                   roles_considered = ['ARG0', 'B-V', 'B-ARGM-NEG', 'B-ARGM-MOD', 'ARG1', 'ARG2'],\n",
    "                   roles_with_known_entities = ['ARG0','ARG1','ARG2'],\n",
    "                   known_entities = top_known_entities,\n",
    "                   assignment_to_known_entities = 'character_matching',\n",
    "                   roles_with_unknown_entities = [['ARG0','ARG1','ARG2']],\n",
    "                   embeddings_model = None,\n",
    "                   threshold = 1)    \n",
    "\n",
    "m.train(postproc_roles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5405c121",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cProfile.run(\"narratives = m.predict(postproc_roles, progress_bar = True)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10b113d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_narratives = []\n",
    "for n in narratives: \n",
    "    if n.get('ARG0') is not None:\n",
    "        if n.get('B-V') is not None:\n",
    "            if n.get('ARG1') is not None:\n",
    "                pretty_narratives.append(prettify(n))\n",
    "                \n",
    "pretty_narratives = Counter(pretty_narratives)\n",
    "for t in pretty_narratives.most_common(10): print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4adb0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from relatio import Embeddings\n",
    "nlp_model = Embeddings(\"TensorFlow_USE\",\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "# nlp_model = Embeddings(\"Gensim_pretrained\", \"glove-twitter-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f10ce93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m = NarrativeModel(model_type = 'static',\n",
    "                   roles_considered = ['ARG0', 'B-V', 'B-ARGM-NEG', 'B-ARGM-MOD', 'ARG1', 'ARG2'],\n",
    "                   roles_with_known_entities = ['ARG0','ARG1','ARG2'],\n",
    "                   known_entities = top_known_entities,\n",
    "                   assignment_to_known_entities = 'embeddings',\n",
    "                   roles_with_unknown_entities = [['ARG0','ARG1','ARG2']],\n",
    "                   n_clusters = [100],\n",
    "                   embeddings_model = nlp_model,\n",
    "                   threshold = 0.3)    \n",
    "\n",
    "m.train(postproc_roles, progress_bar = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cc601a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cProfile.run(\"narratives = m.predict(postproc_roles, progress_bar = True)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4ec2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = NarrativeModel(model_type = 'dynamic',\n",
    "                   roles_considered = ['ARG0', 'B-V', 'B-ARGM-NEG', 'B-ARGM-MOD', 'ARG1', 'ARG2'],\n",
    "                   roles_with_known_entities = ['ARG0','ARG1','ARG2'],\n",
    "                   known_entities = top_known_entities,\n",
    "                   assignment_to_known_entities = 'character_matching',\n",
    "                   roles_with_unknown_entities = [['ARG0','ARG1','ARG2']],\n",
    "                   embeddings_model = nlp_model,\n",
    "                   threshold = 0.3)    \n",
    "\n",
    "m.train(postproc_roles, progress_bar = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c575b4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cProfile.run(\"narratives = m.predict(postproc_roles[0:100], progress_bar = True)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e4bde2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pretty_narratives = []\n",
    "for n in narratives: \n",
    "    pretty_narratives.append(prettify(n))\n",
    "                \n",
    "pretty_narratives = Counter(pretty_narratives)\n",
    "for t in pretty_narratives.most_common(10): print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2080f70",
   "metadata": {},
   "source": [
    "## Step 5: Model validation and basic analysis\n",
    "\n",
    "----------------------------\n",
    "\n",
    "\n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a3161f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "postproc_roles[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8782cdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "narratives[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604af1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "m._model_obj.vectors_unknown_entities[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f810f87f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(m._model_obj.vocab_unknown_entities[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd98434",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pretty_narratives = []\n",
    "for n in narratives: \n",
    "    if n.get('ARG0') not in [\"\", None]:\n",
    "        if n.get('B-V') not in [\"\", None]:\n",
    "            if n.get('ARG1') not in [\"\", None]:\n",
    "                pretty_narratives.append(prettify(n))\n",
    "                \n",
    "pretty_narratives = Counter(pretty_narratives)\n",
    "for t in pretty_narratives.most_common(100): print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a8eb7c",
   "metadata": {},
   "source": [
    "## Step 6: Visualization // Plotting narrative graphs\n",
    "----------------------------\n",
    "\n",
    "A collection of narrative statements has an intuitive network structure, in which the edges are verbs and the nodes are entities.\n",
    "\n",
    "Here, we plot Trump's narrative statements on Twitter.\n",
    "\n",
    "----------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
