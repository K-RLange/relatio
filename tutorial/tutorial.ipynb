{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10bb6bdd",
   "metadata": {},
   "source": [
    "# An introduction to `relatio` \n",
    "**Runtime $\\sim$ 1h**\n",
    "\n",
    "Original paper: [\"Text Semantics Capture Political and Economic Narratives\"](https://arxiv.org/abs/2108.01720)\n",
    "\n",
    "----------------------------\n",
    "\n",
    "This is a short demo of the package `relatio`.  It takes as input a text corpus and outputs a list of narrative statements. The pipeline is unsupervised: the user does not need to specify narratives beforehand. Narrative statements are defined as tuples of semantic roles with a (agent, verb, patient, attribute) structure. \n",
    "\n",
    "Here, we present the main wrapper functions to quickly obtain narrative statements from a corpus.\n",
    "\n",
    "----------------------------\n",
    "\n",
    "We provide datasets that have already been split into sentences and annotated by our team.\n",
    "\n",
    "The datasets are provided in three different formats:\n",
    " 1. `raw` (unprocessed)\n",
    " 2. `split_sentences` (as a list of sentences)\n",
    " 3. `srl` (as a list of annotated sentences by the semantic role labeler)\n",
    "\n",
    "In this tutorial, we work with the Trump Tweet Archive corpus.\n",
    "\n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7121f11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17886d5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-05 10:04:04.068473: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-05 10:04:04.068494: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# Catch warnings for an easy ride\n",
    "from relatio import FileLogger\n",
    "logger = FileLogger(level = 'WARNING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1fe7218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    List of available datasets:\n",
      "\n",
      "    Trump Tweet Archive\n",
      "    - function call: load_trump_data()\n",
      "    - format: 'raw', 'split_sentences', 'srl_res'\n",
      "    - allennlp version: 0.9\n",
      "    - srl model: srl-model-2018.05.25.tar.gz\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Browse list of available datasets\n",
    "from relatio.datasets import list_datasets\n",
    "print(list_datasets())\n",
    "\n",
    "# Load an available dataset\n",
    "from relatio.datasets import load_trump_data\n",
    "df = load_trump_data(\"raw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e04ad8d",
   "metadata": {},
   "source": [
    "## Step 1: Split into sentences\n",
    "\n",
    "----------------------------\n",
    "\n",
    "For any new corpus, the first thing you will want to do is to split the corpus into sentences.\n",
    "\n",
    "We do this on the first 100 tweets. \n",
    "\n",
    "The output is two lists: one with an index for the document and one with the resulting split sentences.\n",
    "\n",
    "----------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d00439a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting into sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1000/1000 [00:01<00:00, 884.93it/s]\n"
     ]
    }
   ],
   "source": [
    "from relatio.preprocessing import *\n",
    "\n",
    "p = Preprocessor(\n",
    "    spacy_model = \"en_core_web_md\",\n",
    "    remove_punctuation = True,\n",
    "    remove_digits = True,\n",
    "    lowercase = True,\n",
    "    lemmatize = True,\n",
    "    stop_words = [],\n",
    "    n_process = -1,\n",
    "    batch_size = 100\n",
    ")\n",
    "\n",
    "split_sentences = p.split_into_sentences(\n",
    "    df.iloc[0:1000], output_path='sentences.json', progress_bar=True\n",
    ")\n",
    "\n",
    "from relatio.utils import load_sentences\n",
    "doc_index, sentences = load_sentences('sentences.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcd1100",
   "metadata": {},
   "source": [
    "## Step 2: Annotate semantic roles\n",
    "\n",
    "----------------------------\n",
    "\n",
    "Once the corpus is split into sentences. You can feed it to the semantic role labeler.\n",
    "\n",
    "The output is a list of json objects which contain the semantic role annotations for each sentence in the corpus.\n",
    "\n",
    "----------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cacb0860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running SRL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 229/229 [01:32<00:00,  2.48it/s]\n"
     ]
    }
   ],
   "source": [
    "from relatio.semantic_role_labeling import SRL\n",
    "\n",
    "SRL = SRL(\n",
    "    path = \"https://storage.googleapis.com/allennlp-public-models/openie-model.2020.03.26.tar.gz\",\n",
    "    batch_size = 10,\n",
    "    cuda_device = 0\n",
    ")\n",
    "\n",
    "srl_res = SRL(split_sentences[1], progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc80c071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbs': [{'verb': 'have',\n",
       "   'description': 'Republicans and Democrats [V: have] both created our economic problems .',\n",
       "   'tags': ['O', 'O', 'O', 'B-V', 'O', 'O', 'O', 'O', 'O', 'O']},\n",
       "  {'verb': 'created',\n",
       "   'description': '[ARG0: Republicans and Democrats] have both [V: created] [ARG1: our economic problems] .',\n",
       "   'tags': ['B-ARG0',\n",
       "    'I-ARG0',\n",
       "    'I-ARG0',\n",
       "    'O',\n",
       "    'O',\n",
       "    'B-V',\n",
       "    'B-ARG1',\n",
       "    'I-ARG1',\n",
       "    'I-ARG1',\n",
       "    'O']}],\n",
       " 'words': ['Republicans',\n",
       "  'and',\n",
       "  'Democrats',\n",
       "  'have',\n",
       "  'both',\n",
       "  'created',\n",
       "  'our',\n",
       "  'economic',\n",
       "  'problems',\n",
       "  '.']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srl_res[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e112b6",
   "metadata": {},
   "source": [
    "NB: This step is faster with a GPU. The argument cuda_device allows users to use their GPUs:\n",
    "\n",
    "```\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())\n",
    "\n",
    "SRL = SRL(\n",
    "    path = \"https://storage.googleapis.com/allennlp-public-models/openie-model.2020.03.26.tar.gz\",\n",
    "    batch_size = 10,\n",
    "    cuda_device = 0\n",
    ")\n",
    "\n",
    "srl_res = SRL(split_sentences[1], progress_bar=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e546d4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save us some time, we download the results from the datasets module.\n",
    "# split_sentences = load_trump_data(\"split_sentences\")\n",
    "# srl_res = load_trump_data(\"srl_res\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28629041",
   "metadata": {},
   "source": [
    "## Step 3: Pre-process semantic roles\n",
    "\n",
    "----------------------------\n",
    "\n",
    "\n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cb56070",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting semantic roles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 2283/2283 [00:00<00:00, 25242.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-V': 'have'}\n",
      "{'ARG0': 'Republicans and Democrats', 'ARG1': 'our economic problems', 'B-V': 'created'}\n",
      "{'ARG1': 'I', 'ARG2': 'thrilled to be back in the Great city of Charlotte , North Carolina with thousands of hardworking American Patriots who love our Country , cherish our values , respect our laws , and always put AMERICA FIRST', 'B-V': 'was'}\n",
      "{'ARG1': 'I', 'ARG2': 'back in the Great city of Charlotte , North Carolina with , respect our laws , and always put AMERICA FIRST', 'B-V': 'be'}\n",
      "{'ARG0': 'thousands of hardworking American Patriots who', 'ARG1': 'our Country', 'B-V': 'love'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from relatio.semantic_role_labeling import extract_roles\n",
    "\n",
    "roles, sentence_index = extract_roles(\n",
    "    srl_res, \n",
    "    used_roles = [\"ARG0\",\"B-V\",\"B-ARGM-NEG\",\"B-ARGM-MOD\",\"ARG1\",\"ARG2\"],\n",
    "    progress_bar = True\n",
    ")\n",
    "\n",
    "for d in roles[0:5]: print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "478392f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning phrases for role ARG0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1873/1873 [00:02<00:00, 845.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning phrases for role B-V...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 4684/4684 [00:06<00:00, 691.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning phrases for role B-ARGM-MOD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 484/484 [00:01<00:00, 406.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning phrases for role ARG1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 3396/3396 [00:04<00:00, 765.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning phrases for role ARG2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 951/951 [00:00<00:00, 1054.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-V': 'have'}\n",
      "{'ARG0': 'republicans democrats', 'B-V': 'create', 'ARG1': 'problem'}\n",
      "{'ARG2': 'city charlotte north carolina thousand patriots country value law america'}\n",
      "{'ARG2': 'city charlotte north carolina law america'}\n",
      "{'ARG0': 'thousand patriots', 'ARG1': 'country'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "postproc_roles = p.process_roles(roles, \n",
    "                                 dict_of_pos_tags_to_keep = {\n",
    "                                     \"ARG0\": ['NOUN', 'PROPN'],\n",
    "                                     \"B-V\": ['VERB'],\n",
    "                                     \"ARG1\": ['NOUN', 'PROPN'],\n",
    "                                     \"ARG2\": ['NOUN', 'PROPN']\n",
    "                                 }, \n",
    "                                 progress_bar = True,\n",
    "                                 output_path = 'postproc_roles.json')\n",
    "\n",
    "from relatio.utils import load_roles\n",
    "postproc_roles = load_roles('postproc_roles.json')\n",
    "\n",
    "for d in postproc_roles[0:5]: print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e627dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mining named entities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 2283/2283 [00:01<00:00, 1230.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('biden', 78)\n",
      "('georgia', 58)\n",
      "('pennsylvania', 53)\n",
      "('joe biden', 50)\n",
      "('trump', 39)\n",
      "('michigan', 35)\n",
      "('democrats', 29)\n",
      "('america', 29)\n",
      "('republican', 27)\n",
      "('breitbartnews', 27)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "known_entities = p.mine_entities(\n",
    "    split_sentences[1], \n",
    "    clean_entities = True, \n",
    "    progress_bar = True,\n",
    "    output_path = 'entities.pkl'\n",
    ")\n",
    "\n",
    "from relatio.utils import load_entities\n",
    "known_entities = load_entities('entities.pkl')\n",
    "\n",
    "for n in known_entities.most_common(10): print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ad2f93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_known_entities = [e[0] for e in list(known_entities.most_common(100)) if e[0] != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fc61ab",
   "metadata": {},
   "source": [
    "## Step 4: Build a narrative model\n",
    "\n",
    "----------------------------\n",
    "\n",
    "We are now ready to build a narrative model.\n",
    "\n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2f75d13d",
   "metadata": {},
   "source": [
    "postproc_roles = [{'B-V': 'have'},\n",
    " {'ARG0': 'republicans democrats', 'B-V': 'create', 'ARG1': 'problem'},\n",
    " {'ARG2': 'city charlotte north carolina thousand patriots country value law america'},\n",
    " {'ARG2': 'city charlotte north carolina law america'},\n",
    " {'ARG0': 'thousand patriots', 'ARG1': 'country'},\n",
    " {'ARG0': 'thousand patriots', 'B-V': 'cherish', 'ARG1': 'value'},\n",
    " {'ARG1': 'law'},\n",
    " {'B-V': 'put', 'ARG1': 'america first'},\n",
    " {'B-V': 'thank', 'ARG2': 'evening'},\n",
    " {'ARG1': 'unsolicited mail ballot scam', 'ARG2': 'threat democracy amp'}]\n",
    "\n",
    "top_known_entities = ['republicans', 'democrats', 'mail allot scam', 'america', 'thousand patriots']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ee9d9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No training required: the model is deterministic.\n"
     ]
    }
   ],
   "source": [
    "from relatio.narrative_models import NarrativeModel\n",
    "from relatio.utils import prettify\n",
    "from collections import Counter\n",
    "\n",
    "m = NarrativeModel(model_type = 'deterministic',\n",
    "                   roles_considered = ['ARG0', 'B-V', 'B-ARGM-NEG', 'B-ARGM-MOD', 'ARG1', 'ARG2'],\n",
    "                   roles_with_known_entities = ['ARG0','ARG1','ARG2'],\n",
    "                   known_entities = top_known_entities,\n",
    "                   assignment_to_known_entities = 'character_matching',\n",
    "                   roles_with_unknown_entities = [['ARG0','ARG1','ARG2']],\n",
    "                   embeddings_model = None,\n",
    "                   threshold = 1)    \n",
    "\n",
    "m.train(postproc_roles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5405c121",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting entities for role: ARG0...\n",
      "Matching known entities (with character matching)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 908/908 [00:00<00:00, 8642.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigning labels to matches...\n",
      "\n",
      "Predicting entities for role: ARG1...\n",
      "Matching known entities (with character matching)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 2424/2424 [00:00<00:00, 7830.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigning labels to matches...\n",
      "\n",
      "Predicting entities for role: ARG2...\n",
      "Matching known entities (with character matching)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 657/657 [00:00<00:00, 8192.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigning labels to matches...\n",
      "         1777582 function calls (1757132 primitive calls) in 0.537 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        9    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1009(_handle_fromlist)\n",
      "        1    0.000    0.000    0.536    0.536 <string>:1(<module>)\n",
      "        3    0.000    0.000    0.000    0.000 _monitor.py:94(report)\n",
      "        3    0.000    0.000    0.000    0.000 _weakrefset.py:106(remove)\n",
      "        6    0.000    0.000    0.000    0.000 _weakrefset.py:16(__init__)\n",
      "        6    0.000    0.000    0.000    0.000 _weakrefset.py:20(__enter__)\n",
      "        6    0.000    0.000    0.000    0.000 _weakrefset.py:26(__exit__)\n",
      "        6    0.000    0.000    0.000    0.000 _weakrefset.py:52(_commit_removals)\n",
      "        9    0.000    0.000    0.000    0.000 _weakrefset.py:58(__iter__)\n",
      "        3    0.000    0.000    0.000    0.000 _weakrefset.py:81(add)\n",
      "  20451/1    0.014    0.000    0.030    0.030 copy.py:132(deepcopy)\n",
      "    15332    0.001    0.000    0.001    0.000 copy.py:190(_deepcopy_atomic)\n",
      "        1    0.002    0.002    0.030    0.030 copy.py:211(_deepcopy_list)\n",
      "     5118    0.006    0.000    0.019    0.000 copy.py:237(_deepcopy_dict)\n",
      "     5119    0.002    0.000    0.002    0.000 copy.py:253(_keep_alive)\n",
      "       83    0.000    0.000    0.001    0.000 iostream.py:208(schedule)\n",
      "        3    0.000    0.000    0.000    0.000 iostream.py:303(fileno)\n",
      "       34    0.000    0.000    0.000    0.000 iostream.py:420(_is_master_process)\n",
      "       34    0.000    0.000    0.000    0.000 iostream.py:439(_schedule_flush)\n",
      "       16    0.000    0.000    0.006    0.000 iostream.py:453(flush)\n",
      "       34    0.000    0.000    0.001    0.000 iostream.py:502(write)\n",
      "       83    0.000    0.000    0.000    0.000 iostream.py:97(_event_pipe)\n",
      "        3    0.000    0.000    0.000    0.000 narrative_models.py:130(<listcomp>)\n",
      "        3    0.148    0.049    0.501    0.167 narrative_models.py:144(_character_matching)\n",
      "        1    0.000    0.000    0.536    0.536 narrative_models.py:493(predict)\n",
      "        1    0.001    0.001    0.536    0.536 narrative_models.py:72(predict)\n",
      "       83    0.001    0.000    0.001    0.000 socket.py:480(send)\n",
      "       19    0.000    0.000    0.000    0.000 std.py:104(acquire)\n",
      "       19    0.000    0.000    0.000    0.000 std.py:108(release)\n",
      "       12    0.000    0.000    0.000    0.000 std.py:112(__enter__)\n",
      "        3    0.000    0.000    0.000    0.000 std.py:1146(__del__)\n",
      "       10    0.000    0.000    0.001    0.000 std.py:1149(__str__)\n",
      "       12    0.000    0.000    0.000    0.000 std.py:115(__exit__)\n",
      "        6    0.000    0.000    0.000    0.000 std.py:1152(_comparable)\n",
      "        6    0.000    0.000    0.000    0.000 std.py:1156(__hash__)\n",
      "     3992    0.002    0.000    0.006    0.000 std.py:1159(__iter__)\n",
      "        4    0.000    0.000    0.003    0.001 std.py:1197(update)\n",
      "        6    0.000    0.000    0.002    0.000 std.py:1264(close)\n",
      "        6    0.000    0.000    0.000    0.000 std.py:1285(fp_write)\n",
      "        3    0.000    0.000    0.000    0.000 std.py:1300(<lambda>)\n",
      "        7    0.000    0.000    0.004    0.001 std.py:1324(refresh)\n",
      "       10    0.000    0.000    0.000    0.000 std.py:1445(format_dict)\n",
      "       10    0.000    0.000    0.006    0.001 std.py:1463(display)\n",
      "       10    0.000    0.000    0.000    0.000 std.py:155(__init__)\n",
      "       10    0.000    0.000    0.000    0.000 std.py:165(colour)\n",
      "       10    0.000    0.000    0.000    0.000 std.py:169(colour)\n",
      "       10    0.000    0.000    0.000    0.000 std.py:188(__format__)\n",
      "        9    0.000    0.000    0.000    0.000 std.py:228(__init__)\n",
      "       27    0.000    0.000    0.000    0.000 std.py:233(__call__)\n",
      "       17    0.000    0.000    0.000    0.000 std.py:288(format_interval)\n",
      "        3    0.000    0.000    0.002    0.001 std.py:329(status_printer)\n",
      "       10    0.000    0.000    0.004    0.000 std.py:342(fp_write)\n",
      "       10    0.000    0.000    0.004    0.000 std.py:348(print_status)\n",
      "       10    0.000    0.000    0.001    0.000 std.py:355(format_meter)\n",
      "        3    0.000    0.000    0.000    0.000 std.py:560(__new__)\n",
      "        3    0.000    0.000    0.000    0.000 std.py:576(_get_free_pos)\n",
      "        3    0.000    0.000    0.000    0.000 std.py:579(<setcomp>)\n",
      "        3    0.000    0.000    0.000    0.000 std.py:583(_decr_instances)\n",
      "        3    0.000    0.000    0.000    0.000 std.py:657(get_lock)\n",
      "        3    0.000    0.000    0.004    0.001 std.py:846(__init__)\n",
      "       99    0.000    0.000    0.000    0.000 threading.py:1050(_wait_for_tstate_lock)\n",
      "       99    0.000    0.000    0.000    0.000 threading.py:1092(is_alive)\n",
      "       16    0.000    0.000    0.000    0.000 threading.py:216(__init__)\n",
      "       16    0.000    0.000    0.000    0.000 threading.py:240(__enter__)\n",
      "       16    0.000    0.000    0.000    0.000 threading.py:243(__exit__)\n",
      "       16    0.000    0.000    0.000    0.000 threading.py:249(_release_save)\n",
      "       16    0.000    0.000    0.000    0.000 threading.py:252(_acquire_restore)\n",
      "       16    0.000    0.000    0.000    0.000 threading.py:255(_is_owned)\n",
      "       16    0.000    0.000    0.005    0.000 threading.py:264(wait)\n",
      "       16    0.000    0.000    0.000    0.000 threading.py:499(__init__)\n",
      "      102    0.000    0.000    0.000    0.000 threading.py:507(is_set)\n",
      "       16    0.000    0.000    0.005    0.000 threading.py:534(wait)\n",
      "        9    0.000    0.000    0.000    0.000 utils.py:101(wrapper_setattr)\n",
      "        3    0.000    0.000    0.000    0.000 utils.py:105(__init__)\n",
      "        6    0.000    0.000    0.000    0.000 utils.py:136(disable_on_exception)\n",
      "       26    0.000    0.000    0.004    0.000 utils.py:143(inner)\n",
      "   398900    0.217    0.000    0.241    0.000 utils.py:159(is_subsequence)\n",
      "        3    0.000    0.000    0.000    0.000 utils.py:162(__init__)\n",
      "        6    0.000    0.000    0.000    0.000 utils.py:171(__eq__)\n",
      "        3    0.000    0.000    0.000    0.000 utils.py:201(_is_utf)\n",
      "        3    0.000    0.000    0.000    0.000 utils.py:215(_supports_unicode)\n",
      "       20    0.000    0.000    0.000    0.000 utils.py:222(_is_ascii)\n",
      "        3    0.000    0.000    0.000    0.000 utils.py:231(_screen_shape_wrapper)\n",
      "        3    0.003    0.001    0.004    0.001 utils.py:259(make_list_from_key)\n",
      "        3    0.000    0.000    0.000    0.000 utils.py:282(_screen_shape_linux)\n",
      "       30    0.000    0.000    0.001    0.000 utils.py:329(_text_width)\n",
      "     2012    0.000    0.000    0.001    0.000 utils.py:330(<genexpr>)\n",
      "       30    0.000    0.000    0.001    0.000 utils.py:333(disp_len)\n",
      "       10    0.000    0.000    0.000    0.000 utils.py:341(disp_trim)\n",
      "       10    0.000    0.000    0.000    0.000 utils.py:57(__init__)\n",
      "       10    0.000    0.000    0.000    0.000 utils.py:61(__format__)\n",
      "        3    0.000    0.000    0.000    0.000 utils.py:74(__eq__)\n",
      "        6    0.000    0.000    0.000    0.000 utils.py:88(__getattr__)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x55c52bbf1d40}\n",
      "       16    0.000    0.000    0.000    0.000 {built-in method _imp.lock_held}\n",
      "       32    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method _weakref.proxy}\n",
      "       16    0.000    0.000    0.000    0.000 {built-in method builtins.abs}\n",
      "       44    0.000    0.000    0.000    0.000 {built-in method builtins.divmod}\n",
      "        1    0.000    0.000    0.537    0.537 {built-in method builtins.exec}\n",
      "       27    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "       41    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
      "    30696    0.002    0.000    0.002    0.000 {built-in method builtins.id}\n",
      "       54    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      "     4052    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "       20    0.000    0.000    0.000    0.000 {built-in method builtins.max}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method builtins.min}\n",
      "      210    0.000    0.000    0.000    0.000 {built-in method builtins.ord}\n",
      "        9    0.000    0.000    0.000    0.000 {built-in method builtins.print}\n",
      "       30    0.000    0.000    0.001    0.000 {built-in method builtins.sum}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method fcntl.ioctl}\n",
      "        7    0.000    0.000    0.000    0.000 {built-in method now}\n",
      "       34    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
      "     2389    0.000    0.000    0.000    0.000 {built-in method time.time}\n",
      "     1982    0.000    0.000    0.000    0.000 {built-in method unicodedata.east_asian_width}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method utcfromtimestamp}\n",
      "       16    0.000    0.000    0.000    0.000 {method '__enter__' of '_thread.lock' objects}\n",
      "       16    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}\n",
      "       19    0.000    0.000    0.000    0.000 {method 'acquire' of '_multiprocessing.SemLock' objects}\n",
      "       19    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.RLock' objects}\n",
      "      163    0.005    0.000    0.005    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "        9    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}\n",
      "       99    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "    23056    0.001    0.000    0.001    0.000 {method 'append' of 'list' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'difference' of 'set' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}\n",
      "       71    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}\n",
      "    56256    0.004    0.000    0.004    0.000 {method 'get' of 'dict' objects}\n",
      "   398900    0.024    0.000    0.024    0.000 {method 'issubset' of 'set' objects}\n",
      "     5118    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "     1457    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}\n",
      "     2532    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}\n",
      "       19    0.000    0.000    0.000    0.000 {method 'release' of '_multiprocessing.SemLock' objects}\n",
      "       19    0.000    0.000    0.000    0.000 {method 'release' of '_thread.RLock' objects}\n",
      "       16    0.000    0.000    0.000    0.000 {method 'release' of '_thread.lock' objects}\n",
      "        9    0.000    0.000    0.000    0.000 {method 'remove' of 'set' objects}\n",
      "   797800    0.100    0.000    0.100    0.000 {method 'split' of 'str' objects}\n",
      "       30    0.000    0.000    0.000    0.000 {method 'sub' of 're.Pattern' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cProfile.run(\"narratives = m.predict(postproc_roles, progress_bar = True)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d10b113d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('biden want country', 2)\n",
      "('republicans|house will vote ndaa|national defense authorization act', 2)\n",
      "('biden lie pennsylvania', 1)\n",
      "('democrats|republican|rino look d.c.', 1)\n",
      "('state want state', 1)\n",
      "('twitter ban pennsylvania|state', 1)\n",
      "('pennsylvania give biden', 1)\n",
      "('fbi must make fbi', 1)\n",
      "('mike have country', 1)\n",
      "('georgia|state refuse republican|kelly|david', 1)\n"
     ]
    }
   ],
   "source": [
    "pretty_narratives = []\n",
    "for n in narratives: \n",
    "    if n.get('ARG0') is not None:\n",
    "        if n.get('B-V') is not None:\n",
    "            if n.get('ARG1') is not None:\n",
    "                pretty_narratives.append(prettify(n))\n",
    "                \n",
    "pretty_narratives = Counter(pretty_narratives)\n",
    "for t in pretty_narratives.most_common(10): print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea4adb0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from relatio import Embeddings\n",
    "#nlp_model = Embeddings(\"TensorFlow_USE\",\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "nlp_model = Embeddings(\"Gensim_pretrained\", \"glove-twitter-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f10ce93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Focus on roles: ARG0-ARG1-ARG2\n",
      "Ignoring known entities...\n",
      "Computing phrase embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 466/466 [00:00<00:00, 20398.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing phrase embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 1400/1400 [00:00<00:00, 21976.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing phrase embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 524/524 [00:00<00:00, 21583.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing phrase embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 2052/2052 [00:00<00:00, 26911.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering phrases into 100 clusters...\n",
      "Labeling the clusters by the most frequent phrases...\n"
     ]
    }
   ],
   "source": [
    "m = NarrativeModel(model_type = 'static',\n",
    "                   roles_considered = ['ARG0', 'B-V', 'B-ARGM-NEG', 'B-ARGM-MOD', 'ARG1', 'ARG2'],\n",
    "                   roles_with_known_entities = ['ARG0','ARG1','ARG2'],\n",
    "                   known_entities = top_known_entities,\n",
    "                   assignment_to_known_entities = 'embeddings',\n",
    "                   roles_with_unknown_entities = [['ARG0','ARG1','ARG2']],\n",
    "                   n_clusters = [100],\n",
    "                   embeddings_model = nlp_model,\n",
    "                   threshold = 0.3)    \n",
    "\n",
    "m.train(postproc_roles, progress_bar = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54cc601a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting entities for role: ARG0...\n",
      "Computing phrase embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 908/908 [00:00<00:00, 10286.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching known entities (with embeddings distance)...\n",
      "Matching unknown entities (with embeddings distance)...\n",
      "Assigning labels to matches...\n",
      "\n",
      "Predicting entities for role: ARG1...\n",
      "Computing phrase embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 2424/2424 [00:00<00:00, 12341.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching known entities (with embeddings distance)...\n",
      "Matching unknown entities (with embeddings distance)...\n",
      "Assigning labels to matches...\n",
      "\n",
      "Predicting entities for role: ARG2...\n",
      "Computing phrase embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 657/657 [00:00<00:00, 12841.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching known entities (with embeddings distance)...\n",
      "Matching unknown entities (with embeddings distance)...\n",
      "Assigning labels to matches...\n",
      "         413121 function calls (388759 primitive calls) in 0.424 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        6    0.000    0.000    0.002    0.000 <__array_function__ internals>:2(amin)\n",
      "        6    0.000    0.000    0.001    0.000 <__array_function__ internals>:2(argmin)\n",
      "        3    0.000    0.000    0.003    0.001 <__array_function__ internals>:2(concatenate)\n",
      "     3912    0.003    0.000    0.011    0.000 <__array_function__ internals>:2(count_nonzero)\n",
      "     3912    0.003    0.000    0.013    0.000 <__array_function__ internals>:2(dot)\n",
      "     3989    0.004    0.000    0.113    0.000 <__array_function__ internals>:2(mean)\n",
      "     3912    0.003    0.000    0.046    0.000 <__array_function__ internals>:2(norm)\n",
      "        6    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(where)\n",
      "        9    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1009(_handle_fromlist)\n",
      "        1    0.000    0.000    0.424    0.424 <string>:1(<module>)\n",
      "      252    0.001    0.000    0.004    0.000 __init__.py:1002(flush)\n",
      "      252    0.001    0.000    0.010    0.000 __init__.py:1013(emit)\n",
      "      252    0.000    0.000    0.010    0.000 __init__.py:1118(emit)\n",
      "      252    0.000    0.000    0.000    0.000 __init__.py:117(getLevelName)\n",
      "      252    0.001    0.000    0.001    0.000 __init__.py:1216(getLogger)\n",
      "      252    0.001    0.000    0.023    0.000 __init__.py:1380(warning)\n",
      "      252    0.001    0.000    0.002    0.000 __init__.py:1446(findCaller)\n",
      "      252    0.000    0.000    0.007    0.000 __init__.py:1476(makeRecord)\n",
      "      252    0.001    0.000    0.022    0.000 __init__.py:1491(_log)\n",
      "      252    0.000    0.000    0.012    0.000 __init__.py:1516(handle)\n",
      "      252    0.000    0.000    0.000    0.000 __init__.py:154(<lambda>)\n",
      "      252    0.001    0.000    0.012    0.000 __init__.py:1570(callHandlers)\n",
      "      252    0.000    0.000    0.000    0.000 __init__.py:1614(isEnabledFor)\n",
      "      252    0.000    0.000    0.002    0.000 __init__.py:1928(getLogger)\n",
      "      252    0.000    0.000    0.000    0.000 __init__.py:2067(handle)\n",
      "      252    0.001    0.000    0.028    0.000 __init__.py:2080(_showwarning)\n",
      "      252    0.000    0.000    0.000    0.000 __init__.py:212(_acquireLock)\n",
      "      252    0.000    0.000    0.000    0.000 __init__.py:221(_releaseLock)\n",
      "      252    0.003    0.000    0.007    0.000 __init__.py:282(__init__)\n",
      "      252    0.000    0.000    0.000    0.000 __init__.py:360(getMessage)\n",
      "      252    0.000    0.000    0.000    0.000 __init__.py:418(usesTime)\n",
      "      252    0.001    0.000    0.001    0.000 __init__.py:421(format)\n",
      "      252    0.001    0.000    0.002    0.000 __init__.py:528(formatTime)\n",
      "      252    0.000    0.000    0.000    0.000 __init__.py:573(usesTime)\n",
      "      252    0.000    0.000    0.001    0.000 __init__.py:579(formatMessage)\n",
      "      252    0.001    0.000    0.005    0.000 __init__.py:595(format)\n",
      "      504    0.000    0.000    0.000    0.000 __init__.py:736(filter)\n",
      "      504    0.000    0.000    0.001    0.000 __init__.py:838(acquire)\n",
      "      504    0.000    0.000    0.000    0.000 __init__.py:845(release)\n",
      "      252    0.000    0.000    0.005    0.000 __init__.py:858(format)\n",
      "      252    0.000    0.000    0.011    0.000 __init__.py:881(handle)\n",
      "     3989    0.033    0.000    0.310    0.000 _embeddings.py:104(get_vector)\n",
      "     3989    0.004    0.000    0.194    0.000 _embeddings.py:144(_get_default_vector)\n",
      "        3    0.010    0.003    0.346    0.115 _embeddings.py:148(_get_vectors)\n",
      "     3989    0.016    0.000    0.190    0.000 _embeddings.py:271(_get_default_vector)\n",
      "     3989    0.007    0.000    0.031    0.000 _embeddings.py:283(<listcomp>)\n",
      "        6    0.000    0.000    0.015    0.002 _embeddings.py:287(_compute_distances)\n",
      "        6    0.000    0.000    0.002    0.000 _embeddings.py:291(_get_min_distances)\n",
      "        6    0.000    0.000    0.001    0.000 _embeddings.py:294(_get_index_min_distances)\n",
      "        6    0.000    0.000    0.018    0.003 _embeddings.py:297(_embeddings_similarity)\n",
      "     3912    0.001    0.000    0.001    0.000 _embeddings.py:95(normalize)\n",
      "     3989    0.001    0.000    0.001    0.000 _embeddings.py:99(use_sif)\n",
      "     3989    0.036    0.000    0.090    0.000 _methods.py:162(_mean)\n",
      "     3989    0.002    0.000    0.013    0.000 _methods.py:54(_any)\n",
      "     3989    0.015    0.000    0.018    0.000 _methods.py:66(_count_reduce_items)\n",
      "        3    0.000    0.000    0.000    0.000 _monitor.py:94(report)\n",
      "        3    0.000    0.000    0.000    0.000 _weakrefset.py:106(remove)\n",
      "        6    0.000    0.000    0.000    0.000 _weakrefset.py:16(__init__)\n",
      "        6    0.000    0.000    0.000    0.000 _weakrefset.py:20(__enter__)\n",
      "        6    0.000    0.000    0.000    0.000 _weakrefset.py:26(__exit__)\n",
      "        6    0.000    0.000    0.000    0.000 _weakrefset.py:52(_commit_removals)\n",
      "        9    0.000    0.000    0.000    0.000 _weakrefset.py:58(__iter__)\n",
      "        3    0.000    0.000    0.000    0.000 _weakrefset.py:81(add)\n",
      "      252    0.000    0.000    0.000    0.000 abc.py:137(__instancecheck__)\n",
      "  20451/1    0.024    0.000    0.050    0.050 copy.py:132(deepcopy)\n",
      "    15332    0.002    0.000    0.002    0.000 copy.py:190(_deepcopy_atomic)\n",
      "        1    0.002    0.002    0.050    0.050 copy.py:211(_deepcopy_list)\n",
      "     5118    0.010    0.000    0.033    0.000 copy.py:237(_deepcopy_dict)\n",
      "     5119    0.003    0.000    0.004    0.000 copy.py:253(_keep_alive)\n",
      "        6    0.000    0.000    0.015    0.002 distance.py:2616(cdist)\n",
      "        6    0.000    0.000    0.000    0.000 fromnumeric.py:1198(_argmin_dispatcher)\n",
      "        6    0.000    0.000    0.001    0.000 fromnumeric.py:1202(argmin)\n",
      "        6    0.000    0.000    0.000    0.000 fromnumeric.py:2758(_amin_dispatcher)\n",
      "        6    0.000    0.000    0.002    0.000 fromnumeric.py:2763(amin)\n",
      "     3989    0.001    0.000    0.001    0.000 fromnumeric.py:3317(_mean_dispatcher)\n",
      "     3989    0.015    0.000    0.104    0.000 fromnumeric.py:3322(mean)\n",
      "        6    0.000    0.000    0.001    0.000 fromnumeric.py:51(_wrapfunc)\n",
      "        6    0.000    0.000    0.002    0.000 fromnumeric.py:69(_wrapreduction)\n",
      "        6    0.000    0.000    0.000    0.000 fromnumeric.py:70(<dictcomp>)\n",
      "      252    0.000    0.000    0.001    0.000 genericpath.py:121(_splitext)\n",
      "       83    0.000    0.000    0.001    0.000 iostream.py:208(schedule)\n",
      "        3    0.000    0.000    0.000    0.000 iostream.py:303(fileno)\n",
      "       43    0.000    0.000    0.000    0.000 iostream.py:420(_is_master_process)\n",
      "       43    0.000    0.000    0.000    0.000 iostream.py:439(_schedule_flush)\n",
      "       13    0.000    0.000    0.006    0.000 iostream.py:453(flush)\n",
      "       43    0.000    0.000    0.001    0.000 iostream.py:502(write)\n",
      "       83    0.000    0.000    0.000    0.000 iostream.py:97(_event_pipe)\n",
      "     8383    0.005    0.000    0.024    0.000 keyedvectors.py:337(__getitem__)\n",
      "     8383    0.010    0.000    0.014    0.000 keyedvectors.py:438(word_vec)\n",
      "     8383    0.004    0.000    0.018    0.000 keyedvectors.py:470(get_vector)\n",
      "     3912    0.002    0.000    0.002    0.000 linalg.py:112(isComplexType)\n",
      "     3912    0.001    0.000    0.001    0.000 linalg.py:2359(_norm_dispatcher)\n",
      "     3912    0.021    0.000    0.040    0.000 linalg.py:2363(norm)\n",
      "      252    0.000    0.000    0.001    0.000 linecache.py:15(getline)\n",
      "      252    0.000    0.000    0.000    0.000 linecache.py:37(getlines)\n",
      "        3    0.000    0.000    0.000    0.000 multiarray.py:148(concatenate)\n",
      "        6    0.000    0.000    0.000    0.000 multiarray.py:341(where)\n",
      "     3912    0.001    0.000    0.001    0.000 multiarray.py:736(dot)\n",
      "        3    0.000    0.000    0.000    0.000 narrative_models.py:130(<listcomp>)\n",
      "        3    0.000    0.000    0.000    0.000 narrative_models.py:164(_label_with_known_entity)\n",
      "        3    0.000    0.000    0.000    0.000 narrative_models.py:165(<listcomp>)\n",
      "        3    0.000    0.000    0.001    0.000 narrative_models.py:167(_label_with_most_frequent_phrase)\n",
      "        3    0.001    0.000    0.001    0.000 narrative_models.py:168(<listcomp>)\n",
      "        1    0.000    0.000    0.424    0.424 narrative_models.py:493(predict)\n",
      "        1    0.002    0.002    0.424    0.424 narrative_models.py:72(predict)\n",
      "     3912    0.001    0.000    0.001    0.000 numeric.py:421(_count_nonzero_dispatcher)\n",
      "     3912    0.002    0.000    0.005    0.000 numeric.py:425(count_nonzero)\n",
      "      252    0.000    0.000    0.001    0.000 posixpath.py:121(splitext)\n",
      "      252    0.000    0.000    0.001    0.000 posixpath.py:144(basename)\n",
      "      252    0.000    0.000    0.000    0.000 posixpath.py:41(_get_sep)\n",
      "      504    0.000    0.000    0.001    0.000 posixpath.py:52(normcase)\n",
      "      252    0.000    0.000    0.000    0.000 process.py:180(name)\n",
      "      252    0.000    0.000    0.000    0.000 process.py:36(current_process)\n",
      "       83    0.001    0.000    0.001    0.000 socket.py:480(send)\n",
      "       16    0.000    0.000    0.000    0.000 std.py:104(acquire)\n",
      "       16    0.000    0.000    0.000    0.000 std.py:108(release)\n",
      "       12    0.000    0.000    0.000    0.000 std.py:112(__enter__)\n",
      "        3    0.000    0.000    0.000    0.000 std.py:1146(__del__)\n",
      "        7    0.000    0.000    0.001    0.000 std.py:1149(__str__)\n",
      "       12    0.000    0.000    0.000    0.000 std.py:115(__exit__)\n",
      "        6    0.000    0.000    0.000    0.000 std.py:1152(_comparable)\n",
      "        6    0.000    0.000    0.000    0.000 std.py:1156(__hash__)\n",
      "     3992    0.005    0.000    0.009    0.000 std.py:1159(__iter__)\n",
      "        1    0.000    0.000    0.001    0.001 std.py:1197(update)\n",
      "        6    0.000    0.000    0.003    0.000 std.py:1264(close)\n",
      "        6    0.000    0.000    0.000    0.000 std.py:1285(fp_write)\n",
      "        3    0.000    0.000    0.000    0.000 std.py:1300(<lambda>)\n",
      "        4    0.000    0.000    0.003    0.001 std.py:1324(refresh)\n",
      "        7    0.000    0.000    0.000    0.000 std.py:1445(format_dict)\n",
      "        7    0.000    0.000    0.005    0.001 std.py:1463(display)\n",
      "        7    0.000    0.000    0.000    0.000 std.py:155(__init__)\n",
      "        7    0.000    0.000    0.000    0.000 std.py:165(colour)\n",
      "        7    0.000    0.000    0.000    0.000 std.py:169(colour)\n",
      "        7    0.000    0.000    0.000    0.000 std.py:188(__format__)\n",
      "        9    0.000    0.000    0.000    0.000 std.py:228(__init__)\n",
      "        9    0.000    0.000    0.000    0.000 std.py:233(__call__)\n",
      "       11    0.000    0.000    0.000    0.000 std.py:288(format_interval)\n",
      "        3    0.000    0.000    0.003    0.001 std.py:329(status_printer)\n",
      "        7    0.000    0.000    0.004    0.001 std.py:342(fp_write)\n",
      "        7    0.000    0.000    0.004    0.001 std.py:348(print_status)\n",
      "        7    0.000    0.000    0.001    0.000 std.py:355(format_meter)\n",
      "        3    0.000    0.000    0.000    0.000 std.py:560(__new__)\n",
      "        3    0.000    0.000    0.000    0.000 std.py:576(_get_free_pos)\n",
      "        3    0.000    0.000    0.000    0.000 std.py:579(<setcomp>)\n",
      "        3    0.000    0.000    0.000    0.000 std.py:583(_decr_instances)\n",
      "        3    0.000    0.000    0.000    0.000 std.py:657(get_lock)\n",
      "        3    0.000    0.000    0.005    0.002 std.py:846(__init__)\n",
      "       96    0.000    0.000    0.000    0.000 threading.py:1050(_wait_for_tstate_lock)\n",
      "      252    0.000    0.000    0.000    0.000 threading.py:1064(name)\n",
      "       96    0.000    0.000    0.000    0.000 threading.py:1092(is_alive)\n",
      "      252    0.000    0.000    0.000    0.000 threading.py:1225(current_thread)\n",
      "       13    0.000    0.000    0.000    0.000 threading.py:216(__init__)\n",
      "       13    0.000    0.000    0.000    0.000 threading.py:240(__enter__)\n",
      "       13    0.000    0.000    0.000    0.000 threading.py:243(__exit__)\n",
      "       13    0.000    0.000    0.000    0.000 threading.py:249(_release_save)\n",
      "       13    0.000    0.000    0.000    0.000 threading.py:252(_acquire_restore)\n",
      "       13    0.000    0.000    0.000    0.000 threading.py:255(_is_owned)\n",
      "       13    0.000    0.000    0.005    0.000 threading.py:264(wait)\n",
      "       13    0.000    0.000    0.000    0.000 threading.py:499(__init__)\n",
      "       99    0.000    0.000    0.000    0.000 threading.py:507(is_set)\n",
      "       13    0.000    0.000    0.006    0.000 threading.py:534(wait)\n",
      "        9    0.000    0.000    0.000    0.000 utils.py:101(wrapper_setattr)\n",
      "        3    0.000    0.000    0.000    0.000 utils.py:105(__init__)\n",
      "        6    0.000    0.000    0.000    0.000 utils.py:136(disable_on_exception)\n",
      "       20    0.000    0.000    0.004    0.000 utils.py:143(inner)\n",
      "        3    0.000    0.000    0.000    0.000 utils.py:162(__init__)\n",
      "        6    0.000    0.000    0.000    0.000 utils.py:171(__eq__)\n",
      "        3    0.000    0.000    0.000    0.000 utils.py:201(_is_utf)\n",
      "        3    0.000    0.000    0.000    0.000 utils.py:215(_supports_unicode)\n",
      "       14    0.000    0.000    0.000    0.000 utils.py:222(_is_ascii)\n",
      "        3    0.000    0.000    0.000    0.000 utils.py:231(_screen_shape_wrapper)\n",
      "        3    0.003    0.001    0.005    0.002 utils.py:259(make_list_from_key)\n",
      "        3    0.000    0.000    0.000    0.000 utils.py:282(_screen_shape_linux)\n",
      "       21    0.000    0.000    0.001    0.000 utils.py:329(_text_width)\n",
      "     1401    0.000    0.000    0.000    0.000 utils.py:330(<genexpr>)\n",
      "       21    0.000    0.000    0.001    0.000 utils.py:333(disp_len)\n",
      "        7    0.000    0.000    0.000    0.000 utils.py:341(disp_trim)\n",
      "        7    0.000    0.000    0.000    0.000 utils.py:57(__init__)\n",
      "        7    0.000    0.000    0.000    0.000 utils.py:61(__format__)\n",
      "        3    0.000    0.000    0.000    0.000 utils.py:74(__eq__)\n",
      "        6    0.000    0.000    0.000    0.000 utils.py:88(__getattr__)\n",
      "      252    0.000    0.000    0.003    0.000 warnings.py:15(formatwarning)\n",
      "      252    0.002    0.000    0.002    0.000 warnings.py:35(_formatwarnmsg_impl)\n",
      "      504    0.001    0.000    0.001    0.000 warnings.py:415(__init__)\n",
      "      252    0.001    0.000    0.029    0.000 warnings.py:96(_showwarnmsg)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x55c52bbf1d40}\n",
      "      252    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}\n",
      "       13    0.000    0.000    0.000    0.000 {built-in method _imp.lock_held}\n",
      "       26    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}\n",
      "      504    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}\n",
      "      439    0.004    0.000    0.034    0.000 {built-in method _warnings.warn}\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method _weakref.proxy}\n",
      "       13    0.000    0.000    0.000    0.000 {built-in method builtins.abs}\n",
      "      258    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\n",
      "       29    0.000    0.000    0.000    0.000 {built-in method builtins.divmod}\n",
      "        1    0.000    0.000    0.424    0.424 {built-in method builtins.exec}\n",
      "       33    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "     1120    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
      "    30696    0.003    0.000    0.003    0.000 {built-in method builtins.id}\n",
      "    18188    0.004    0.000    0.004    0.000 {built-in method builtins.isinstance}\n",
      "    15802    0.003    0.000    0.003    0.000 {built-in method builtins.issubclass}\n",
      "      834    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "       14    0.000    0.000    0.000    0.000 {built-in method builtins.max}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method builtins.min}\n",
      "      147    0.000    0.000    0.000    0.000 {built-in method builtins.ord}\n",
      "       15    0.000    0.000    0.001    0.000 {built-in method builtins.print}\n",
      "       21    0.000    0.000    0.001    0.000 {built-in method builtins.sum}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method fcntl.ioctl}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method now}\n",
      "     3989    0.008    0.000    0.008    0.000 {built-in method numpy.array}\n",
      "     3989    0.011    0.000    0.011    0.000 {built-in method numpy.asanyarray}\n",
      "     3924    0.001    0.000    0.001    0.000 {built-in method numpy.asarray}\n",
      "     3912    0.003    0.000    0.003    0.000 {built-in method numpy.core._multiarray_umath.count_nonzero}\n",
      "15746/11834    0.021    0.000    0.164    0.000 {built-in method numpy.core._multiarray_umath.implement_array_function}\n",
      "     3989    0.001    0.000    0.001    0.000 {built-in method numpy.core._multiarray_umath.normalize_axis_index}\n",
      "       77    0.000    0.000    0.000    0.000 {built-in method numpy.empty}\n",
      "     1008    0.000    0.000    0.000    0.000 {built-in method posix.fspath}\n",
      "      295    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
      "        6    0.015    0.002    0.015    0.002 {built-in method scipy.spatial._distance_pybind.cdist_euclidean}\n",
      "      252    0.000    0.000    0.000    0.000 {built-in method sys._getframe}\n",
      "      252    0.001    0.000    0.001    0.000 {built-in method time.localtime}\n",
      "      252    0.001    0.000    0.001    0.000 {built-in method time.strftime}\n",
      "     3088    0.001    0.000    0.001    0.000 {built-in method time.time}\n",
      "     1380    0.000    0.000    0.000    0.000 {built-in method unicodedata.east_asian_width}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method utcfromtimestamp}\n",
      "       13    0.000    0.000    0.000    0.000 {method '__enter__' of '_thread.lock' objects}\n",
      "       13    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}\n",
      "       16    0.000    0.000    0.000    0.000 {method 'acquire' of '_multiprocessing.SemLock' objects}\n",
      "      772    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.RLock' objects}\n",
      "      148    0.005    0.000    0.005    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "        9    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}\n",
      "       77    0.000    0.000    0.001    0.000 {method 'any' of 'numpy.generic' objects}\n",
      "     3912    0.003    0.000    0.016    0.000 {method 'any' of 'numpy.ndarray' objects}\n",
      "       96    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "    30586    0.003    0.000    0.003    0.000 {method 'append' of 'list' objects}\n",
      "        6    0.001    0.000    0.001    0.000 {method 'argmin' of 'numpy.ndarray' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'difference' of 'set' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}\n",
      "      252    0.000    0.000    0.000    0.000 {method 'find' of 'str' objects}\n",
      "      252    0.003    0.000    0.003    0.000 {method 'flush' of '_io.TextIOWrapper' objects}\n",
      "       47    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}\n",
      "    56766    0.006    0.000    0.006    0.000 {method 'get' of 'dict' objects}\n",
      "     5124    0.001    0.000    0.001    0.000 {method 'items' of 'dict' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}\n",
      "       77    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}\n",
      "     3912    0.002    0.000    0.002    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
      "     7984    0.035    0.000    0.035    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "       16    0.000    0.000    0.000    0.000 {method 'release' of '_multiprocessing.SemLock' objects}\n",
      "      772    0.000    0.000    0.000    0.000 {method 'release' of '_thread.RLock' objects}\n",
      "       13    0.000    0.000    0.000    0.000 {method 'release' of '_thread.lock' objects}\n",
      "        9    0.000    0.000    0.000    0.000 {method 'remove' of 'set' objects}\n",
      "      756    0.000    0.000    0.000    0.000 {method 'rfind' of 'str' objects}\n",
      "     8383    0.005    0.000    0.005    0.000 {method 'setflags' of 'numpy.ndarray' objects}\n",
      "     7978    0.003    0.000    0.003    0.000 {method 'split' of 'str' objects}\n",
      "      252    0.000    0.000    0.000    0.000 {method 'strip' of 'str' objects}\n",
      "       21    0.000    0.000    0.000    0.000 {method 'sub' of 're.Pattern' objects}\n",
      "        7    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}\n",
      "      252    0.000    0.000    0.000    0.000 {method 'write' of '_io.TextIOWrapper' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cProfile.run(\"narratives = m.predict(postproc_roles, progress_bar = True)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52e4bde2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('', 1155)\n",
      "('have', 151)\n",
      "('do', 127)\n",
      "('thank', 55)\n",
      "('go', 48)\n",
      "('get', 46)\n",
      "('vote', 34)\n",
      "('see', 28)\n",
      "('win', 27)\n",
      "('taxis', 22)\n"
     ]
    }
   ],
   "source": [
    "pretty_narratives = []\n",
    "for n in narratives: \n",
    "    pretty_narratives.append(prettify(n))\n",
    "                \n",
    "pretty_narratives = Counter(pretty_narratives)\n",
    "for t in pretty_narratives.most_common(10): print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2080f70",
   "metadata": {},
   "source": [
    "## Step 5: Model validation and basic analysis\n",
    "\n",
    "----------------------------\n",
    "\n",
    "\n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57a3161f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'B-V': 'have'},\n",
       " {'ARG0': 'republicans democrats', 'B-V': 'create', 'ARG1': 'problem'},\n",
       " {'ARG2': 'city charlotte north carolina thousand patriots country value law america'},\n",
       " {'ARG2': 'city charlotte north carolina law america'},\n",
       " {'ARG0': 'thousand patriots', 'ARG1': 'country'},\n",
       " {'ARG0': 'thousand patriots', 'B-V': 'cherish', 'ARG1': 'value'},\n",
       " {'ARG1': 'law'},\n",
       " {'B-V': 'put', 'ARG1': 'america first'},\n",
       " {'B-V': 'thank', 'ARG2': 'evening'},\n",
       " {'ARG1': 'unsolicited mail ballot scam', 'ARG2': 'threat democracy amp'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postproc_roles[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8782cdbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'B-V': 'have'},\n",
       " {'ARG0': 'result', 'B-V': 'create', 'ARG1': 'job'},\n",
       " {'ARG2': 'administration'},\n",
       " {'ARG2': 'republican'},\n",
       " {'ARG0': 'military', 'ARG1': 'dominion voting systems'},\n",
       " {'ARG0': 'military', 'B-V': 'cherish', 'ARG1': 'governor briankempga'},\n",
       " {'ARG1': 'fake news'},\n",
       " {'B-V': 'put', 'ARG1': 'republican poll watcher'},\n",
       " {'B-V': 'thank', 'ARG2': 'biden'},\n",
       " {'ARG1': 'signature verification', 'ARG2': 'mistake'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "narratives[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f810f87f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('job', 26),\n",
       " ('child', 6),\n",
       " ('biden corruption', 3),\n",
       " ('mail ballot', 3),\n",
       " ('stench election hoax', 3),\n",
       " ('terrorist anarchist agitator antifa', 3),\n",
       " ('term', 3),\n",
       " ('signature envelope ballot', 2),\n",
       " ('price transparency', 2),\n",
       " ('businessman jobs life', 2),\n",
       " ('going', 2),\n",
       " ('u.s. energy industry fracking energy gas price', 2),\n",
       " ('taxis brave law enforcement wall second amendment', 2),\n",
       " ('ballot loss america', 2),\n",
       " ('november 3rd', 2),\n",
       " ('department justice department homeland security u.s. supreme court', 1),\n",
       " ('democrat senate', 1),\n",
       " ('bret baier tweet', 1),\n",
       " ('way shape form', 1),\n",
       " ('order', 1),\n",
       " ('star pennsylvania', 1),\n",
       " ('alfred e. newman mayor pete amp', 1),\n",
       " ('misery', 1),\n",
       " ('man woman secretservice', 1),\n",
       " ('drug price', 1),\n",
       " ('victory country', 1),\n",
       " ('information', 1),\n",
       " ('job president', 1),\n",
       " ('covid covid covid way election', 1),\n",
       " ('law amp order', 1),\n",
       " ('stephaniebice', 1),\n",
       " ('joe bidenim wing medium big tech giant washington swamp', 1),\n",
       " ('voter fraud place election', 1)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m._model_obj.vocab_unknown_entities[0][90].most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "afd98434",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('law have clue', 5)\n",
      "('decision have clue', 5)\n",
      "('sleepy joe have sleepy joe', 2)\n",
      "('term super predator have clue', 2)\n",
      "('law enforcement would not allow guy', 2)\n",
      "('election draw vote', 2)\n",
      "('sleepy joe steal troop', 2)\n",
      "('state have clue', 2)\n",
      "('result steal troop', 2)\n",
      "('election sacrifice world', 2)\n",
      "('election vow friend', 2)\n",
      "('election abolish friend', 2)\n",
      "('sleepy joe will vote fake news', 2)\n",
      "('signature have america', 2)\n",
      "('way have clue', 2)\n",
      "('result create job', 1)\n",
      "('military cherish governor briankempga', 1)\n",
      "('troop use court', 1)\n",
      "('classified information agree president united states', 1)\n",
      "('result have thug lowlife', 1)\n",
      "('election lie taxis', 1)\n",
      "('poll run troop', 1)\n",
      "('court would announce problem', 1)\n",
      "('democrat cities have point', 1)\n",
      "('donald trump have point', 1)\n",
      "('radical left would destroy vote', 1)\n",
      "('result not want news media', 1)\n",
      "('result have news media', 1)\n",
      "('oann have politician', 1)\n",
      "('oann reject light', 1)\n",
      "('donald trump allow consent decree', 1)\n",
      "('election expose great red wave', 1)\n",
      "('water make politician', 1)\n",
      "('vote not want america', 1)\n",
      "('sleepy joe steal news media', 1)\n",
      "('speech find result', 1)\n",
      "('vaccine say result', 1)\n",
      "('speech tell point', 1)\n",
      "('america look news media', 1)\n",
      "('radical left democrats come biden', 1)\n",
      "('sleepy joe get senator', 1)\n",
      "('result will let clark county official', 1)\n",
      "('result not let law', 1)\n",
      "('way continue mistake', 1)\n",
      "('way get mistake', 1)\n",
      "('election overcome vote', 1)\n",
      "('signature want breitbartnews', 1)\n",
      "('signature approve mistake', 1)\n",
      "('word send republican poll watcher', 1)\n",
      "('signature want recount', 1)\n",
      "('signature correct recount', 1)\n",
      "('mistake not receive usa', 1)\n",
      "('dominion voting systems needs america', 1)\n",
      "('word ban oann', 1)\n",
      "('joe biden want case', 1)\n",
      "('donald trump give military', 1)\n",
      "('word give election', 1)\n",
      "('speech nominate america', 1)\n",
      "('great red wave not allow donald trump', 1)\n",
      "('donald trump look vote', 1)\n",
      "('signature want senator', 1)\n",
      "('win use recount', 1)\n",
      "('outcome election must make regulation', 1)\n",
      "('decision pay country', 1)\n",
      "('biden get amp', 1)\n",
      "('poll say senator', 1)\n",
      "('senator would get dem', 1)\n",
      "('clark county official toy job', 1)\n",
      "('way have dominion voting systems', 1)\n",
      "('signature certify case', 1)\n",
      "('recount may overturn radical left democrats', 1)\n",
      "('voter fraud information set supreme court', 1)\n",
      "('vote expose troop', 1)\n",
      "('joe biden talk guy', 1)\n",
      "('country do case', 1)\n",
      "('oann refuse consent decree', 1)\n",
      "('oann let consent decree', 1)\n",
      "('democrats would expose military', 1)\n",
      "('democrats give state book', 1)\n",
      "('election sell ballot', 1)\n",
      "('republican poll watcher rake wisconsin', 1)\n",
      "('republican poll watcher lose case', 1)\n",
      "('win watch fake news', 1)\n",
      "('religious liberty shut donald trump', 1)\n",
      "('state have vote', 1)\n",
      "('observer must open president united states', 1)\n",
      "('observer must call observer', 1)\n",
      "('republican state regulation', 1)\n",
      "('michigan refuse guy', 1)\n",
      "('michigan sign guy', 1)\n",
      "('election spy recount', 1)\n",
      "('vote will not accept troop', 1)\n",
      "('administration will have world', 1)\n",
      "('america make oann', 1)\n",
      "('america put result', 1)\n",
      "('donald trump not allow dem', 1)\n",
      "('poll stop book', 1)\n",
      "('republican not have fake news', 1)\n",
      "('georgia take regulation', 1)\n",
      "('win have job', 1)\n"
     ]
    }
   ],
   "source": [
    "pretty_narratives = []\n",
    "for n in narratives: \n",
    "    if n.get('ARG0') not in [\"\", None]:\n",
    "        if n.get('B-V') not in [\"\", None]:\n",
    "            if n.get('ARG1') not in [\"\", None]:\n",
    "                pretty_narratives.append(prettify(n))\n",
    "                \n",
    "pretty_narratives = Counter(pretty_narratives)\n",
    "for t in pretty_narratives.most_common(100): print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a8eb7c",
   "metadata": {},
   "source": [
    "## Step 6: Visualization // Plotting narrative graphs\n",
    "----------------------------\n",
    "\n",
    "A collection of narrative statements has an intuitive network structure, in which the edges are verbs and the nodes are entities.\n",
    "\n",
    "Here, we plot Trump's narrative statements on Twitter.\n",
    "\n",
    "----------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
