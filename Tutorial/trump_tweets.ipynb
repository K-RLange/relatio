{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "attempted-analyst",
   "metadata": {},
   "source": [
    "### Settings and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "nominated-payroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import numpy as np \n",
    "from numpy.linalg import norm\n",
    "\n",
    "from typing import Dict, List, NamedTuple, Optional, Tuple\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "import gensim.downloader as api\n",
    "model = api.load(\"glove-wiki-gigaword-300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-opening",
   "metadata": {},
   "source": [
    "### All functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-discount",
   "metadata": {},
   "outputs": [],
   "source": [
    "blerg = {'ARGO':{'considered': True, 'embeddings': True, 'entities': True},\n",
    "         'B-V':{'considered': True, 'embeddings': False, 'entities': False},\n",
    "         'B-ARGM-MOD':{'considered': True, 'embeddings': False, 'entities': False},\n",
    "         'B-ARGM-NEG':{'considered': True, 'embeddings': False, 'entities': False},\n",
    "         'ARG1':{'considered': True, 'embeddings': True, 'entities': True},\n",
    "         'ARG2':{'considered': True, 'embeddings': True, 'entities': True}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-acquisition",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'roles_considered': ['ARGO', 'B-V', 'B-ARGM-NEG', 'B-ARGM-MOD', 'ARG1', 'ARG2'],\n",
    "          'roles_with_embeddings': ['ARGO', 'ARG1', 'ARG2'],\n",
    "          'roles_with_entities': ['ARGO', 'ARG1', 'ARG2']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "differential-flush",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../code')\n",
    "\n",
    "# Utils\n",
    "#..................................................................................................................\n",
    "#..................................................................................................................\n",
    "\n",
    "def split_into_sentences(\n",
    "    docs: List[str]\n",
    ") -> List[str]:\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    A function that splits a list of documents into sentences (using the SpaCy sentence splitter).\n",
    "    \n",
    "    Args:\n",
    "        docs: list of docs\n",
    "        \n",
    "    Returns:\n",
    "        List of sentences\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    sentences = []\n",
    "    \n",
    "    for doc in docs:\n",
    "        temp = [str(i) for i in nlp(doc).sents]\n",
    "        sentences = temp + sentences\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "from utils import preprocess\n",
    "\n",
    "# Semantic Role Labeling\n",
    "#..................................................................................................................\n",
    "#..................................................................................................................\n",
    "\n",
    "#link to choose the SRL model \n",
    "# https://storage.googleapis.com/allennlp-public-models/YOUR-PREFERRED-MODEL\n",
    "\n",
    "# Would be nice to track the semantic role labeling's progress (given how long it takes) +\n",
    "# code needs to be refactored (remove modals = True)\n",
    "\n",
    "from semantic_role_labeling import SRL, extract_roles, postprocess_roles\n",
    "\n",
    "# Named Entity Recognition\n",
    "#..................................................................................................................\n",
    "#..................................................................................................................\n",
    "\n",
    "def mine_entities(\n",
    "    sentences: List[str],\n",
    "    ent_labels: Optional[List[str]] = ['PERSON', 'NORP', 'ORG', 'GPE', 'EVENT']\n",
    ") -> List[Tuple[str, int]]:\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    A function that goes through sentences and counts named entities found in the corpus.\n",
    "    \n",
    "    Args:\n",
    "        sentences: list of sentences\n",
    "        ent_labels: list of entity labels to be considered (see SPaCy documentation)\n",
    "        \n",
    "    Returns:\n",
    "        List of tuples with the named entity and its associated frequency on the corpus\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    entities_all = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence = nlp(sentence)\n",
    "        for ent in sentence.ents:\n",
    "            if ent.label_ in ent_labels:\n",
    "                entity = [ent.text]\n",
    "                entities_all = entity + entities_all\n",
    "\n",
    "    entities_all = preprocess(entities_all) \n",
    "\n",
    "    entity_counts = Counter(entities_all)\n",
    "    entities_sorted = sorted(entity_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return entities_sorted\n",
    "\n",
    "def pick_top_entities(\n",
    "    entities_sorted: List[Tuple[str,int]],\n",
    "    top_n: Optional[int] = 0\n",
    ") -> List[str]:\n",
    "   \n",
    "    \"\"\"\n",
    "    \n",
    "    A function that returns the top n most frequent named entities in the corpus.\n",
    "    \n",
    "    Args:\n",
    "        entities_sorted: list of tuples (named_entity, frequency)\n",
    "        top_n: number of named entities to keep (default is top 10% and is specified with top_n = 0)\n",
    "        \n",
    "    Returns:\n",
    "        List of most frequent named entities\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if top_n == 0:\n",
    "        top_n = round(len(entities_sorted)/10)\n",
    "    \n",
    "    entities = []\n",
    "\n",
    "    for entity in entities_sorted:\n",
    "        entities = entities + [entity[0]]\n",
    "    \n",
    "    return entities[0:top_n]\n",
    "\n",
    "def is_subsequence(\n",
    "    v2: list, \n",
    "    v1: list\n",
    ") -> bool:\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Check whether v2 is a subsequence of v1.\n",
    "    \n",
    "    Args:\n",
    "        v2/v1: lists of elements\n",
    "        \n",
    "    Returns:\n",
    "        a boolean\n",
    "    \n",
    "    Example:\n",
    "        >>> v1 = ['the', 'united', 'states', 'of', 'america']\\n\n",
    "        ... v2 = ['united', 'states', 'of', 'europe']\\n\n",
    "        ... is_subsequence(v2,v1)\n",
    "        False\n",
    "    \n",
    "    \"\"\"\n",
    "    it = iter(v1)\n",
    "    return all(c in it for c in v2) \n",
    "\n",
    "# Here, the roles matter. \n",
    "\n",
    "def map_entities(\n",
    "    statements: List[dict],\n",
    "    entities: list,\n",
    "    entity_index: Optional[dict] = {},\n",
    "    roles: Optional[List[str]] = ['ARGO', 'ARG1']\n",
    ") -> Tuple[int, dict, List[dict]]:\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    A function that goes through statements and identifies pre-defined named entities within postprocessed semantic roles.\n",
    "    \n",
    "    Args:\n",
    "        statements: list of dictionaries of postprocessed semantic roles\n",
    "        entities: user-defined list of named entities \n",
    "        entity_index: a dictionary \n",
    "        roles: a list of roles with named entities (default = ARG0 and ARG1)\n",
    "        \n",
    "    Returns:\n",
    "        entity_index: updated dictionary\n",
    "        roles_copy: new list of postprocessed semantic roles (without the named entities mined since they will not be embedded)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # roles = params['roles_with_entities']\n",
    "    \n",
    "    if entity_index == {}:\n",
    "        entity_index = {role:{entity:np.asarray([], dtype=int) for entity in entities} for role in roles}\n",
    "    \n",
    "    roles_copy = deepcopy(statements)\n",
    "    \n",
    "    for i, statement in enumerate(statements):\n",
    "        for role, tokens in statements[i].items():\n",
    "            if role in roles:\n",
    "                for entity in entities:\n",
    "                    if is_subsequence(entity.split(), tokens)  == True: \n",
    "                        entity_index[role][entity] = np.append(entity_index[role][entity], [i]) \n",
    "                        roles_copy[i][role] = []\n",
    "    \n",
    "    return entity_index, roles_copy\n",
    "\n",
    "# Vectors and Clustering\n",
    "#..................................................................................................................\n",
    "#..................................................................................................................\n",
    "\n",
    "def count_words(\n",
    "    sentences: List[str]\n",
    ") -> dict:\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    A function that computes word frequencies in a list of sentences.\n",
    "    \n",
    "    Args:\n",
    "        sentences: list of sentences\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary {\"word\": frequency}\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    words = []\n",
    "    \n",
    "    for sentence in processed_sentences:\n",
    "        words = words + sentence.split()\n",
    "\n",
    "    word_count_dict = dict(Counter(words))\n",
    "    \n",
    "    return word_count_dict\n",
    "\n",
    "def compute_sif_weights(\n",
    "    word_count_dict: dict,\n",
    "    alpha: Optional[float] = 0.001\n",
    ") -> dict:\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    A function that computes SIF weights based on word frequencies.\n",
    "    \n",
    "    Args:\n",
    "        word_count_dict: a dictionary {\"word\": frequency}\n",
    "        alpha: regularization parameter (see original paper)\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary {\"word\": SIF weight}\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    sif_dict = {}\n",
    "    \n",
    "    for word, count in word_count_dict.items():\n",
    "        sif_dict[word] = alpha / (alpha + count)\n",
    "\n",
    "    return sif_dict\n",
    "\n",
    "\n",
    "# Here, the roles matter.\n",
    "\n",
    "from utils import get_role_counts\n",
    "\n",
    "def get_vector(\n",
    "    tokens: List[str],\n",
    "    sif_dict: dict,\n",
    "    normalize: Optional[bool] = True\n",
    "):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    A function that computes an embedding vector for a list of tokens.\n",
    "    \n",
    "    Args:\n",
    "        sif_dict: a dictionary {\"word\": SIF weight}\n",
    "        \n",
    "    Returns:\n",
    "        A two-dimensional numpy array (1,dimension of the embedding space)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if not tokens:\n",
    "        res = None\n",
    "    elif any(token not in sif_dict for token in tokens):\n",
    "        res = None\n",
    "    elif any(token not in model.vocab for token in tokens): \n",
    "        res = None \n",
    "    else:\n",
    "        res = np.mean(\n",
    "                [sif_dict[token] * model[token] for token in tokens], axis=0 \n",
    "            )\n",
    "        if normalize:\n",
    "            res = res / norm(res)\n",
    "        \n",
    "        res = np.array([res])\n",
    "        \n",
    "    return res\n",
    "\n",
    "def train_cluster_model(\n",
    "    postproc_roles,\n",
    "    sif_dict,\n",
    "    n_clusters,\n",
    "    random_state: Optional[int] = 0\n",
    "):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    A function to train a kmeans model on the corpus.\n",
    "    \n",
    "    Args:\n",
    "        postproc_roles: list of statements\n",
    "        sif_dict: a dictionary {\"word\": SIF weight}\n",
    "        n_clusters: number of clusters\n",
    "        random_state: seed for replication (default is 0)\n",
    "        \n",
    "    Returns:\n",
    "        A sklearn kmeans model\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    role_counts = get_role_counts(postproc_roles, roles = ['ARGO', 'ARG1']) # params['roles_with_embeddings']\n",
    "    role_counts = list(role_counts)\n",
    "    role_counts = [role.split() for role in role_counts]\n",
    "\n",
    "    vecs = None\n",
    "    for role in role_counts:\n",
    "        if vecs is None:\n",
    "            vecs = get_vector(role, sif_dict)\n",
    "        else:\n",
    "            temp = get_vector(role, sif_dict)\n",
    "            if temp is not None:\n",
    "                vecs = np.concatenate((vecs, temp), axis=0)\n",
    "            \n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state).fit(vecs)\n",
    "    \n",
    "    return kmeans\n",
    "\n",
    "# Here, the roles matter.\n",
    "\n",
    "def get_clusters(\n",
    "    postproc_roles: List[dict],\n",
    "    sif_dict: dict,\n",
    "    kmeans\n",
    ") -> List[dict]:\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    A function which predicts clusters based on a pre-trained kmeans model.\n",
    "    \n",
    "    Args:\n",
    "        postproc_roles: list of statements\n",
    "        sif_dict: a dictionary {\"word\": SIF weight}\n",
    "        kmeans = a pre-trained sklearn kmeans model\n",
    "        \n",
    "    Returns:\n",
    "        A list of dictionaries with the predicted cluster for each role\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    clustering_res = []\n",
    "    for statement in postproc_roles:\n",
    "        temp = {}\n",
    "        for role, tokens in statement.items():\n",
    "            if role in ['ARGO', 'ARG1']: # params['roles_with_embeddings']\n",
    "                vec = get_vector(tokens, sif_dict)\n",
    "                if vec is not None:\n",
    "                    clu = kmeans.predict(vec)\n",
    "                    temp[role] = int(clu)\n",
    "        clustering_res = clustering_res + [temp]\n",
    "\n",
    "    return clustering_res\n",
    "\n",
    "def label_clusters_most_freq(\n",
    "    clustering_res: List[dict],\n",
    "    postproc_roles: List[dict]\n",
    ") -> dict:\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    A function which labels clusters by their most frequent term.\n",
    "    \n",
    "    Args:\n",
    "        clustering_res: list of dictionaries with the predicted cluster for each role\n",
    "        postproc_roles: list of statements\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary associating to each cluster number a label (e.g. the most frequent term in this cluster)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    temp = {}\n",
    "    labels = {}\n",
    "\n",
    "    for i,statement in enumerate(clustering_res):\n",
    "        for role, cluster in statement.items():\n",
    "            tokens = ' '.join(postproc_roles_without_entities[i][role])\n",
    "            cluster_num = cluster\n",
    "            if cluster_num not in temp:\n",
    "                temp[cluster_num] = [tokens]\n",
    "            else:\n",
    "                temp[cluster_num] = temp[cluster_num] + [tokens]\n",
    "\n",
    "    for cluster_num, tokens in temp.items():\n",
    "        token_counts = Counter(tokens)\n",
    "        token_freq = sorted(token_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "        most_freq_token = token_freq[0][0]\n",
    "        labels[cluster_num] = most_freq_token\n",
    "\n",
    "    return labels\n",
    "\n",
    "# Final Narratives\n",
    "#..................................................................................................................\n",
    "#..................................................................................................................\n",
    "\n",
    "# Here, the roles matter. \n",
    "\n",
    "def get_narratives(\n",
    "    postproc_roles: List[dict],\n",
    "    clustering_res: List[dict],\n",
    "    labels: dict\n",
    "):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    A wrapper function to obtain the final mined narratives.\n",
    "    \n",
    "    Args:\n",
    "        postproc_roles: list of statements\n",
    "        clustering_res: list of dictionaries with the predicted cluster for each role\n",
    "        labels: dictionary associating to each cluster number a label (e.g. the most frequent term in this cluster)\n",
    "        \n",
    "    Returns:\n",
    "        A list of dictionaries with the mined narratives.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    final_statements = []\n",
    "    \n",
    "    for statement in postproc_roles:\n",
    "        temp = {}\n",
    "        for role, tokens in statement.items():\n",
    "            name = role + '-RAW'\n",
    "            if type(tokens)!=bool:\n",
    "                temp[name] = ' '.join(tokens)\n",
    "            else:\n",
    "                temp[name] = tokens\n",
    "        final_statements = final_statements + [temp]\n",
    "    \n",
    "    for i,statement in enumerate(clustering_res):\n",
    "        for role, cluster in statement.items():\n",
    "            final_statements[i][role] = labels[cluster]\n",
    "            \n",
    "    for role in ['ARGO', 'ARG1']: # params['roles_with_entities']\n",
    "        for token, indices in entity_index[role].items():\n",
    "            for index in indices:\n",
    "                final_statements[index][role] = token\n",
    "                \n",
    "    return final_statements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-dream",
   "metadata": {},
   "source": [
    "### Pipeline in Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hourly-basement",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/germain/miniconda3/envs/narrative-nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  import sys\n",
      "/home/germain/miniconda3/envs/narrative-nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('trump_tweets.csv')\n",
    "splitted_text = df['text'].str.split()\n",
    "indices = [i for i,value in enumerate(splitted_text) if 'RT' not in value]\n",
    "df = df.loc[indices]\n",
    "df['text'] = df['text'].str.replace(r\"http\\S+\", \"\")\n",
    "df['text'] = df['text'].str.replace(r\"@\\S+\", \"\")\n",
    "df = df[df['text'].str.strip() != '']\n",
    "df = pd.DataFrame(list(zip(df.index, df.text)), columns = ['id', 'doc'])\n",
    "\n",
    "docs = list(df['doc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "rental-bernard",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = split_into_sentences(docs[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "mysterious-reserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "srl = SRL(\"../srl-model-2018.05.25.tar.gz\")\n",
    "srl_res = srl(sentences=sentences, batch_size = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "grateful-paintball",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process_srl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "coordinated-resolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "roles, sentence_index = extract_roles(srl_res, start = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "organic-container",
   "metadata": {},
   "outputs": [],
   "source": [
    "postproc_roles = postprocess_roles(roles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "mighty-clear",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acquired-comedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_sorted = mine_entities(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "incomplete-jaguar",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = pick_top_entities(entities_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "static-founder",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "entity_index, postproc_roles_without_entities = map_entities(statements = postproc_roles,\n",
    "                                                                          entities = entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-conditions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train cluster model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "prerequisite-contemporary",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_sentences = preprocess(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "religious-thirty",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_count_dict = count_words(processed_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "awful-court",
   "metadata": {},
   "outputs": [],
   "source": [
    "sif_dict = compute_sif_weights(word_count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "conservative-employer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4233/4233 [00:00<00:00, 260570.45it/s]\n"
     ]
    }
   ],
   "source": [
    "kmeans = train_cluster_model(postproc_roles, sif_dict, n_clusters = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "honey-bidding",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_res = get_clusters(postproc_roles_without_entities, sif_dict, kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "rough-efficiency",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = label_clusters_most_freq(clustering_res=clustering_res, postproc_roles=postproc_roles_without_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-dover",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get narratives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "functional-deposit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARGO-RAW</th>\n",
       "      <th>ARG1-RAW</th>\n",
       "      <th>B-V-RAW</th>\n",
       "      <th>ARG1</th>\n",
       "      <th>ARG2-RAW</th>\n",
       "      <th>ARGO</th>\n",
       "      <th>B-ARGM-MOD-RAW</th>\n",
       "      <th>B-ARGM-NEG-RAW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the rinos that</td>\n",
       "      <td>the state voting apparatus</td>\n",
       "      <td>run</td>\n",
       "      <td>state</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the rinos that run the state voting apparatus</td>\n",
       "      <td>this problem of allowing the democrats to so b...</td>\n",
       "      <td>caused</td>\n",
       "      <td>election</td>\n",
       "      <td>us</td>\n",
       "      <td>state</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>the democrats to so blatantly cheat in their a...</td>\n",
       "      <td>allowing</td>\n",
       "      <td>election</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the democrats</td>\n",
       "      <td>in their attempt to steal the election which w...</td>\n",
       "      <td>cheat</td>\n",
       "      <td>election</td>\n",
       "      <td>NaN</td>\n",
       "      <td>democrats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the</td>\n",
       "      <td>the election which we won overwhelmingly</td>\n",
       "      <td>steal</td>\n",
       "      <td>election</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4228</th>\n",
       "      <td>hardworking american patriots who</td>\n",
       "      <td>our laws</td>\n",
       "      <td>respect</td>\n",
       "      <td>the</td>\n",
       "      <td>NaN</td>\n",
       "      <td>american</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4229</th>\n",
       "      <td>hardworking american patriots who</td>\n",
       "      <td>america</td>\n",
       "      <td>put</td>\n",
       "      <td>america</td>\n",
       "      <td>NaN</td>\n",
       "      <td>american</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4230</th>\n",
       "      <td>NaN</td>\n",
       "      <td>you</td>\n",
       "      <td>thank</td>\n",
       "      <td>i</td>\n",
       "      <td>for a wonderful evening</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4231</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4232</th>\n",
       "      <td>republicans and democrats</td>\n",
       "      <td>our economic problems</td>\n",
       "      <td>created</td>\n",
       "      <td>the</td>\n",
       "      <td>NaN</td>\n",
       "      <td>republicans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4233 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           ARGO-RAW  \\\n",
       "0                                    the rinos that   \n",
       "1     the rinos that run the state voting apparatus   \n",
       "2                                               NaN   \n",
       "3                                     the democrats   \n",
       "4                                               the   \n",
       "...                                             ...   \n",
       "4228              hardworking american patriots who   \n",
       "4229              hardworking american patriots who   \n",
       "4230                                            NaN   \n",
       "4231                                            NaN   \n",
       "4232                      republicans and democrats   \n",
       "\n",
       "                                               ARG1-RAW   B-V-RAW      ARG1  \\\n",
       "0                            the state voting apparatus       run     state   \n",
       "1     this problem of allowing the democrats to so b...    caused  election   \n",
       "2     the democrats to so blatantly cheat in their a...  allowing  election   \n",
       "3     in their attempt to steal the election which w...     cheat  election   \n",
       "4              the election which we won overwhelmingly     steal  election   \n",
       "...                                                 ...       ...       ...   \n",
       "4228                                           our laws   respect       the   \n",
       "4229                                            america       put   america   \n",
       "4230                                                you     thank         i   \n",
       "4231                                                NaN       NaN       NaN   \n",
       "4232                              our economic problems   created       the   \n",
       "\n",
       "                     ARG2-RAW         ARGO B-ARGM-MOD-RAW B-ARGM-NEG-RAW  \n",
       "0                         NaN          NaN            NaN            NaN  \n",
       "1                          us        state            NaN            NaN  \n",
       "2                         NaN          NaN            NaN            NaN  \n",
       "3                         NaN    democrats            NaN            NaN  \n",
       "4                         NaN          the            NaN            NaN  \n",
       "...                       ...          ...            ...            ...  \n",
       "4228                      NaN     american            NaN            NaN  \n",
       "4229                      NaN     american            NaN            NaN  \n",
       "4230  for a wonderful evening          NaN            NaN            NaN  \n",
       "4231                      NaN          NaN            NaN            NaN  \n",
       "4232                      NaN  republicans            NaN            NaN  \n",
       "\n",
       "[4233 rows x 8 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(get_narratives(postproc_roles, clustering_res, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collect-evening",
   "metadata": {},
   "source": [
    "### Model Validation and Analysis\n",
    "\n",
    "- To be discussed later on.\n",
    "- Add inspect_label()\n",
    "- Add plot_multgraph()\n",
    "- Wrapper to determine the amount of dimension reduction required for clustering?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
